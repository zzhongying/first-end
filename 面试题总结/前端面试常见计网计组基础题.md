# 一、计网

## 一、HTTP协议 

### 1.GET和POST的请求的区别 :

Post 和 Get 是 HTTP 请求的两种方法，其区别如下：

- **应用场景**：GET 请求是一个幂等的请求，一般 **Get 请求用于对服务器资源不会产生影响的场景**，比如说请求、筛选一个网页的资源。而 Post 不是一个幂等的请求，一**般用于对服务器资源会产生影响的情景**，比如注册用户、写入数据这一类的操作。(幂等表示执行相同的操作，结果也是相同的)
- **是否缓存**：因为两者应用场景不同，浏览器一般会对 Get 请求缓存，但很少对 Post 请求缓存。
- **参数类型**：post 的参数传递支持更多的数据类型，支持query参数、params参数和请求体参数。GET请求不支持请求体，只支持query参数和params参数。GET参数通过URL传递，参数之间以&相连。post能发送更多的数据类型（get只能发送ASCII字符）
- **安全性**：Get 请求可以将请求的参数放入 url 中向服务器发送，这样的做法相对于 Post 请求来说是不太安全的，因为请求的 url 会被保留在历史记录中。（最直观的区别：<u>GET把参数包含在URL中</u>，POST通过request <u>body 传递参数</u>，在url中不可见）。post更安全（不会作为url的一部分，不会被缓存、保存在服务器日志、以及浏览器浏览记录中）
- **请求长度：**浏览器由于对 url 长度的限制，所以会影响 get 请求发送数据时的长度。而POST不用考虑请求参数的长度
- **发送的报文格式**：Get 请求的报文中实体部分为空，Post 请求的报文中实体部分一般为向服务器发送的数据。
- **get比post更快**：GET 请求产生一个 TCP 数据包，而POST请求产生俩个 TCP 数据包，
  - post请求包含更多的请求头
     因为post需要在请求的body部分包含数据，所以会多了几个数据描述部分的首部字段（如：content-type）,这其实是微乎其微的。
  - post在真正发送数据之前会先将请求头发送给服务器**进行确认**，然后才真正发送数据（请求体）
     post请求的过程：
     （1）浏览器请求tcp连接（第一次握手）
     （2）服务器答应进行tcp连接（第二次握手）
     （3）浏览器确认，并发送post请求头（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
     （4）服务器返回100 Continue响应
     （5）浏览器发送数据（请求体中的内容）
     （6）服务器返回200 OK响应
     get请求的过程：
     （1）浏览器请求tcp连接（第一次握手）
     （2）服务器答应进行tcp连接（第二次握手）
     （3）浏览器确认，并发送get请求头和数据（第三次握手，这个报文比较小，所以http会在此时进行第一次数据发送）
     （4）服务器返回200 OK响应
     也就是说，目测get的总耗是post的2/3左右，这个口说无凭，网上已经有网友进行过测试。

### 2.常见的HTTP请求方法

- GET: 向服务器获取数据；
- POST：将实体提交到指定的资源，通常会造成服务器资源的修改；
- PUT：上传文件，更新数据；
- DELETE：删除服务器上的对象；
- HEAD：获取报文首部，与GET相比，不返回报文主体部分；
- OPTIONS：询问支持的请求方法，用来跨域请求；
- CONNECT：要求在与代理服务器通信时建立隧道，使用隧道进行TCP通信；
- TRACE: 回显服务器收到的请求，主要⽤于测试或诊断。

### 3.OPTIONS请求方法及使用场景

OPTIONS是除了GET和POST之外的其中一种 HTTP请求方法。

OPTIONS方法是用于请求获得由Request-URI标识的资源在请求/响应的通信过程中可以使用的功能选项。通过这个方法，客户端可以在采取具体资源请求之前，决定对该资源采取何种必要措施，或者了解服务器的性能。该请求方法的响应不能缓存。

OPTIONS请求方法的主要用途有两个：

- 获取服务器支持的所有HTTP请求方法；
- 用来检查访问权限。例如：在进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。

### 4.HTTP协议（应用层）

全称：超文本传输协议

#### 1.HTTP 1.0 和 HTTP 1.1 之间有哪些区别？ 

HTTP 1.0和 HTTP 1.1 有以下区别：

- **连接方面**，http1.0 默认使用非持久连接，即一个tcp连接只传输一个Web对象；http1.1 通过使用持久连接来使多个 http 请求复用同一个 TCP 连接，减少了建立和关闭连接的消耗和延迟。HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
- 资源请求方面，在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，**http1.1 则在请求头引入了 range 头域**，它允许只请求资源的某个部分，即返回码是 206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。HTTP 1.1还允许客户端不用等待上一次请求结果返回，就可以发出下一次请求，但服务器端必须按照接收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每次请求的响应内容，这样也显著地减少了整个下载过程所需要的时间，即为http管道机制。
- 缓存方面，在 http1.0 中主要使用 header 里的 **If-Modified-Since、Expires** 来做为缓存判断的标准，If-Modified-Since头域使用的是绝对时间戳，精确到秒，但使用绝对时间会带来不同机器上的时钟同步问题。**http1.1 则引入了更多的缓存控制策略**，例如 Etag（判断缓存对应的MD5编码是否发生变化）、Cache-Control(max-age指令支持相对时间戳)、If-Unmodified-Since、If-Match、If-None-Match 等更多可供选择的缓存头来控制缓存策略。
- **http1.1 中新增了 host 字段，用来指定服务器的域名**。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。因此有了 host 字段，这样就可以将请求发往到同一台服务器上的不同网站。
- http1.1 相对于 http1.0 还**新增了很多请求方法**，如 PUT、HEAD、OPTIONS 等。HTTP/1.0中只定义了**16个状态响应码**，对错误或警告的提示不够具体。HTTP/1.1引入了一个Warning头域，增加对错误或警告信息的描述。此外，在HTTP/1.1中新增了**24个状态响应码**，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

#### 2.HTTP 1.1 和 HTTP 2.0 的区别 ?

> http2.0的目标是改善用户在使用web时的速度体验
>
> - 压缩
> - 多路复用
> - TLS义务化
> - 协商
> - 服务器推送
> - 浏览控制
> - Websocket
>
> 在http2.0中，客户端在发送请求时会将每个请求的内容封装成不同的带有编号的二进制帧（Frame），然后将这些帧同时发送给服务端。服务端接收到数据之后，会将相同编号的帧合并为完整的请求信息。同样，服务端返回结果、客户端接收结果也遵循这个帧的拆分与组合的过程。
>
> 有了二进制分帧后，对于同一个域，客户端只需要与服务端建立一个连接即可完成通信需求，这种利用一个连接来发送多个请求的方式称为**多路复用**。每一条路都被称为一个` stream（流）`。

- **二进制协议**：HTTP/2 是一个**二进制协议**。在 **HTTP/1.1 版中，报文的头信息必须是文本（ASCII 编码**），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，**头信息和数据体都是二进制，并且统称为"帧"，可以分为头信息帧和数据帧**。 帧的概念是它实现多路复用的基础。

- **多路复用**：http2.0废弃了1.0中的管道，同一个TCP连接中，客户端和服务器可以同时发送多个请求和多个响应，并且不用按照顺序来。连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面，解决了“队头堵塞”问题

  >队头阻塞是由 HTTP 基本的“请求 - 应答”模型所导致的。HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求是没有优先级的，只有入队的先后顺序，排在最前面的请求会被最优先处理。如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本，造成了队头堵塞的现象。

- 数据流：HTTP/2 使用了数据流的概念，因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的请求。因此，必须要对数据包做标记，指出它属于哪个请求。HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。**每个数据流都有一个独一无二的编号**。数据包发送时，都必须标记数据流 ID ，用来区分它属于哪个数据流。最后，客户端还能指定数据流的优先级，优先级越高，服务器会越快做出响应。

- **header压缩**：HTTP/2 实现了头信息压缩，由于 HTTP 1.1 协议不带状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如 Cookie 和 User Agent ，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。HTTP/2 对这一点做了优化，引入了头信息压缩机制。，**客户端和服务器同时维护一张header fields表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号**，这样就能提高速度了。

  >假定一个页面有100个资源需要加载（这个数量对于今天的Web而言还是挺保守的）, 而每一次请求都有1kb的消息头（这同样也并不少见，因为Cookie和引用等东西的存在）, 则至少需要多消耗100kb来获取这些消息头。HTTP2.0可以维护一个字典，差量更新HTTP头部，大大降低因头部传输产生的流量

- **服务器推送**：HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送。使用服务器推送提前给客户端推送必要的资源，这样就可以相对减少一些延迟时间。这里需要注意的是 http2 下服务器主动推送的是静态资源，和 WebSocket 以及使用 SSE 等方式向客户端发送即时数据的推送是不同的。

>HTTP 2.0缺点： 当 TCP 数据包在传输过程中丢失时，在服务器重新发送丢失的	数据包之前，接收方无法确认传入的数据包。由于 TCP 在设计上不遵循 HTTP 之类的高级协议，因此单个丢失的数据包将阻塞所有进行中的 HTTP 请求的流，直到重新发送丢失的数据为止。

![image-20220705211806751](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705211806751.png)

#### 3.HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？

- HTTP/1.* 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；
- HTTP/1.1 Pipeling解决方式为，若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞；
- HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

#### 4.HTTP3.0 

HTTP/2 由于采用二进制分帧进行多路复用，通常只使用一个 TCP 连接进行传输，在丢包或网络中断的情况下后面的所有数据都被阻塞。HTTP3 背后的主要思想是放弃 TCP，在传输层使用基于UDP协议，实现了类似于TCP的多路复用数据流、传输可靠性等功能，这套功能被称为QUIC协议。

1. 流量控制、传输可靠性功能：QUIC在UDP的基础上增加了一层来保证数据传输可靠性，它提供了数据包重传、拥塞控制、以及其他一些TCP中的特性。
2. 集成TLS加密功能：目前QUIC使用TLS1.3，减少了握手所花费的RTT数。
3. 多路复用：同一物理连接上可以有多个独立的逻辑数据流，实现了数据流的单独传输，解决了TCP的队头阻塞问题。
4. 快速握手：由于基于UDP，可以实现使用0 ~ 1个RTT来建立连接。
5. 实现了一套新的拥塞控制算法，彻底解决TCP中队头阻塞的问题

![image-20220705154127177](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705154127177.png)

>由于这次是视频面试，我通常会问你觉得牛客网的视频面试是用的TCP还是UDP呢？在我揭晓答案之前大家也可以想想使用的是哪个网络协议，在面试的过程中所有的同学都回答了应该是使用的是UDP。我问为什么使用UDP?基本都会回答道UDP是一个无连接的协议，不用保证可靠性，传输速度快。我又问道如果UDP不保证可靠性，咱们在视频面试的时候我问你问题，如果你回答问题的视频流丢包了，那么你的答案我就听不见了，那视频面试的体验将会非常低。不少同学在这个时候就会改答案说那应该使用的是TCP吧，我这是又会问道TCP由于需要保证可靠性，但是在公网的复杂环境下，想必应该经常会出现缓冲或者卡顿的现象吧，很多同学这个时候就会哑口无言了。
>
>其实这个问题的答案不难想出，我们可以将TCP和UDP的特性互相结合起来，让这个协议既可以保证可靠性，又可以保证实时性，这也就是我们所说的**RUDP（(Reliable UDP），常见的RUDP协议有QUIC,WebRTC,Aeron等等**，我这里主要介绍谷歌提出的QUIC，带大家领略一下RUDP的精彩，看看他们是如何既能做到可靠又能保证效率。
>
>

#### 6.keep-alive的理解

HTTP1.0 中默认是在每次请求/应答，客户端和服务器都要新建一个连接，完成之后立即断开连接，这就是短连接。当使用Keep-Alive模式时，Keep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接，这就是长连接。其使用方法如下：

- HTTP1.0版本是默认没有Keep-alive的（也就是默认会发送keep-alive），所以要想连接得到保持，必须手动配置发送Connection: keep-alive字段。若想断开keep-alive连接，需发送Connection:close字段；
- HTTP1.1规定了默认保持长连接，数据传输完成了保持TCP连接不断开，等待在同域名下继续用这个通道传输数据。如果需要关闭，需要客户端发送Connection：close首部字段。

#### 7.页面有多张图片，HTTP是怎样的加载表现？

- 在HTTP 1下，浏览器对一个域名下最大TCP连接数为6，所以会请求多次。可以用多域名部署解决。这样可以提高同时请求的数目，加快页面图片的获取速度。
- 在HTTP 2下，可以一瞬间加载出来很多资源，因为，HTTP2支持多路复用，可以在一个TCP连接中发送多个HTTP请求。

#### 8.Http中的请求报文

请求报⽂有4部分组成: 请求⾏ 、请求头部 、空⾏、请求体 

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705160534126.png" alt="image-20220705160534126" style="zoom:67%;" />

#### 9.Http中的响应报文

请求报⽂有4部分组成: 响应⾏ 、响应头 、空⾏、响应体 

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705160733224.png" alt="image-20220705160733224" style="zoom:67%;" />

#### 10.HTTP协议的优点和缺点

HTTP 是超文本传输协议，它定义了客户端和服务器之间交换报文的格式和方式，默认使用 80 端口。它使用 TCP 作为传输层协议，保证了数据传输的可靠性。

HTTP协议具有以下优点：

- 支持客户端/服务器模式
- 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。
- 无连接：无连接就是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接，采用这种方式可以节省传输时间。
- 无状态：HTTP 协议是无状态协议，这里的状态是指通信过程的上下文信息。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能会导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就比较快。
- 灵活：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。

HTTP协议具有以下缺点：

- 无状态：HTTP 是一个无状态的协议，HTTP 服务器不会保存关于客户的任何信息。
- 明文传输：协议中的报文使用的是文本形式，这就直接暴露给外界，不安全。
- 不安全
  （1）通信使用明文（不加密），内容可能会被窃听；
  （2）不验证通信方的身份，因此有可能遭遇伪装；
  （3）无法证明报文的完整性，所以有可能已遭篡改；

### 5.HTTPS协议

#### 1.定义

超文本传输安全协议（Hypertext Transfer Protocol Secure，简称：HTTPS）是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，利用SSL/TLS来加密数据包。HTTPS的主要目的是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

#### 2.HTTPS握手过程

HTTPS的通信过程如下：

1. 客户端向服务器发起请求，请求中包含使用的协议版本号、生成的一个随机数、以及客户端支持的加密方法。
2. 服务器端接收到请求后，确认双方使用的加密方法、并给出服务器的证书、以及一个服务器生成的随机数。
3. 客户端确认服务器证书有效后，生成一个新的随机数，并使用数字证书中的公钥，加密这个随机数，然后发给服 务器。并且还会提供一个前面所有内容的 hash 的值，用来供服务器检验。
4. 服务器使用自己的私钥，来解密客户端发送过来的随机数。并提供前面所有内容的 hash 值来供客户端检验。
5. 客户端和服务器端根据约定的加密方法使用前面的三个随机数，生成对话秘钥，以后的对话过程都使用这个秘钥来加密信息。

#### 3.HTTPS 和HTTP的区别

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705162629519.png" alt="image-20220705162629519" style="zoom:50%;" />

HTTP和HTTPS协议的主要区别如下：

- HTTPS协议需要CA证书，费用较高；而HTTP协议不需要；
- HTTP协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险，而协议TLS/SSL具有身份验证、信息加密和完整性校验的功能，可以避免此类问题发生
- 使用不同的连接方式，端口也不同，HTTP协议端口是80，HTTPS协议端口是443；
- HTTP协议连接很简单，是无状态的；HTTPS协议是有SSL和HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP更加安全。

#### 4.HTTPS是如何保证安全的？

结合两种加密⽅式，将对称加密的密钥使⽤⾮对称加密的公钥进⾏加密，然后发送出去，接收⽅使⽤私钥进⾏解密得到对称加密的密钥，然后双⽅可以使⽤对称加密来进⾏沟通。 

此时⼜带来⼀个问题，中间⼈问题： 
如果此时在客户端和服务器之间存在⼀个中间⼈,这个中间⼈只需要把原本双⽅通信互发的公钥,换成⾃⼰的公钥,这样中间⼈就可以轻松解密通信双⽅所发送的所有数据。 

所以这个时候需要⼀个安全的第三⽅颁发证书（CA），证明身份的身份，防⽌被中间⼈攻击。 证书中包括：签发者、证书⽤途、使⽤者公钥、使⽤者私钥、使⽤者的HASH算法、证书到期时间等。

但是问题来了，如果中间⼈篡改了证书，那么身份证明是不是就⽆效了？这个证明就⽩买了，这个时候需要⼀个新的技术，数字签名。 

数字签名就是⽤CA⾃带的HASH算法对证书的内容进⾏HASH得到⼀个摘要，再⽤CA的私钥加密，最终组成数字签名。当别⼈把他的证书发过来的时候,我再⽤同样的Hash算法,再次⽣成消息摘要，然后⽤CA的公钥对数字签名解密,得到CA创建的消息摘要,两者⼀⽐,就知道中间有没有被⼈篡改了。这个时候就能最⼤程度保证通信的安全了。 

#### 5.HTTPS的优缺点

HTTPS的优点如下：

- 使用HTTPS协议可以认证用户和服务器，确保数据发送到正确的客户端和服务器；
- 使用HTTPS协议可以进行加密传输、身份认证，通信更加安全，防止数据在传输过程中被窃取、修改，确保数据安全性；
- HTTPS是现行架构下最安全的解决方案，虽然不是绝对的安全，但是大幅增加了中间人攻击的成本；

HTTPS的缺点如下：

- HTTPS需要做服务器和客户端双方的加密个解密处理，耗费更多服务器资源，过程复杂；
- HTTPS协议握手阶段比较费时，增加页面的加载时间；
- SSL证书是收费的，功能越强大的证书费用越高；
- HTTPS连接服务器端资源占用高很多，支持访客稍多的网站需要投入更大的成本；
- SSL证书需要绑定IP，不能再同一个IP上绑定多个域名。

#### 6.TLS/SSL的工作原理

TLS/SSL全称安全传输层协议（Transport Layer Security）, 是介于TCP和HTTP之间的一层安全协议，不影响原有的TCP协议和HTTP协议，所以使用HTTPS基本上不需要对HTTP页面进行太多的改造。

TLS/SSL的功能实现主要依赖三类基本算法：散列函数hash、对称加密、非对称加密。这三类算法的作用如下：

- 基于散列函数验证信息的完整性：常见的散列函数有MD5、SHA1、SHA256。该函数的特点是单向不可逆，对输入数据非常敏感，输出的长度固定，任何数据的修改都会改变散列函数的结果，可以用于防止信息篡改并验证数据的完整性。
- 对称加密算法采用协商的秘钥对数据加密：对称加密的优势就是信息传输使用一对一，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和N个客户端通信，需要维持N个密码记录且不能修改密码。常见的对称加密算法有AES-CBC、DES、3DES、AES-GCM等
- 非对称加密实现身份认证和秘钥协商：非对称加密的特点就是信息一对多，服务器只需要维持一个私钥就可以和多个客户端进行通信，但服务器发出的信息能够被所有的客户端解密，且该算法的计算复杂，加密的速度慢。常见的非对称加密算法有RSA、ECC、DH等。

![image-20220705162851507](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705162851507.png)

#### 7.浏览器的并发请求

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220718211756318.png" alt="image-20220718211756318" style="zoom:80%;" />

chrome 浏览器同域名下资源加载的最大并发连接数为6，当资源文件大于6时，多于6个的文件就会进入待定，等第一批加载完才会加载第二批的6个图片资源，这样就增加了等待时间。无形中就增加用户加载网页等待的时间；

解决方法：

1.将多个小图标图片，合并为一张（雪碧图），减少图片数量和http请求

2.使用打包工具合并css和js，减少文件数量，减少http请求

3.将静态资源分布在不同的DNS服务器中，使用多个域名，增加并发量

4.前后端分离，减少不必要的cookie提交

5.设置合理的客户端缓存过期时间

6.图片按需加载

### 6.当在浏览器中输入 Google.com 并且按下回车之后发生了什么？

1. **解析URL：**首先会对 URL 进行解析，分析所需要使用的传输协议和请求的资源的路径。如果输入的 URL 中的协议或者主机名不合法，将会把地址栏中输入的内容传递给搜索引擎。如果没有问题，浏览器会检查 URL 中是否出现了非法字符，如果存在非法字符，则对非法字符进行转义后再进行下一过程。
2. **缓存判断**：浏览器会判断所请求的资源是否在缓存里，如果请求的资源在缓存里并且没有失效，那么就直接使用，否则向服务器发起新的请求。
3. **DNS解析**：下一步首先需要获取的是输入的 URL 中的域名的 IP 地址，首先会判断本地是否有该域名的 IP 地址的缓存，如果有则使用，如果没有则向本地 DNS 服务器发起请求。本地 DNS 服务器也会先检查是否存在缓存，如果没有就会先向根域名服务器发起请求，获得负责的顶级域名服务器的地址后，再向顶级域名服务器请求，然后获得负责的权威域名服务器的地址后，再向权威域名服务器发起请求，最终获得域名的 IP 地址后，本地 DNS 服务器再将这个 IP 地址返回给请求的用户。用户向本地 DNS 服务器发起请求属于递归请求，本地 DNS 服务器向各级域名服务器发起请求属于迭代请求。
4. **获取MAC地址：**当浏览器得到 IP 地址后，数据传输还需要知道目的主机 MAC 地址，因为应用层下发数据给传输层，TCP 协议会指定源端口号和目的端口号，然后下发给网络层。网络层会将本机地址作为源地址，获取的 IP 地址作为目的地址。然后将下发给数据链路层，数据链路层的发送需要加入通信双方的 MAC 地址，本机的 MAC 地址作为源 MAC 地址，目的 MAC 地址需要分情况处理。通过将 IP 地址与本机的子网掩码相与，可以判断是否与请求主机在同一个子网里，如果在同一个子网里，可以使用 APR 协议获取到目的主机的 MAC 地址，如果不在一个子网里，那么请求应该转发给网关，由它代为转发，此时同样可以通过 ARP 协议来获取网关的 MAC 地址，此时目的主机的 MAC 地址应该为网关的地址。
5. **TCP三次握手**：下面是 TCP 建立连接的三次握手的过程，首先客户端向服务器发送一个 SYN 连接请求报文段和一个随机序号，服务端接收到请求后向服务器端发送一个 SYN ACK报文段，确认连接请求，并且也向客户端发送一个随机序号。客户端接收服务器的确认应答后，进入连接建立的状态，同时向服务器也发送一个ACK 确认报文段，服务器端接收到确认后，也进入连接建立状态，此时双方的连接就建立起来了。
6. **HTTPS握手**：如果使用的是 HTTPS 协议，在通信前还存在 TLS 的一个四次握手的过程。首先由客户端向服务器端发送使用的协议的版本号、一个随机数和可以使用的加密方法。服务器端收到后，确认加密的方法，也向客户端发送一个随机数和自己的数字证书。客户端收到后，首先检查数字证书是否有效，如果有效，则再生成一个随机数，并使用证书中的公钥对随机数加密，然后发送给服务器端，并且还会提供一个前面所有内容的 hash 值供服务器端检验。服务器端接收后，使用自己的私钥对数据解密，同时向客户端发送一个前面所有内容的 hash 值供客户端检验。这个时候双方都有了三个随机数，按照之前所约定的加密方法，使用这三个随机数生成一把秘钥，以后双方通信前，就使用这个秘钥对数据进行加密后再传输。
7. **返回数据：**当页面请求发送到服务器端后，服务器端会返回一个 html 文件作为响应，浏览器接收到响应后，开始对 html 文件进行解析，开始页面的渲染过程。
8. **页面渲染：**浏览器首先会根据 html 文件构建 DOM 树，根据解析到的 css 文件构建 CSSOM 树，如果遇到 script 标签，则判端是否含有 defer 或者 async 属性，要不然 script 的加载和执行会造成页面的渲染的阻塞。当 DOM 树和 CSSOM 树建立好后，根据它们来构建渲染树。渲染树构建好后，会根据渲染树来进行布局。布局完成后，最后使用浏览器的 UI 接口对页面进行绘制。这个时候整个页面就显示出来了。
9. **TCP四次挥手：**最后一步是 TCP 断开连接的四次挥手过程。若客户端认为数据发送完成，则它需要向服务端发送连接释放请求。服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明客户端到服务端的连接已经释放，不再接收客户端发的数据了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。服务端如果此时还有没发完的数据会继续发送，完毕后会向客户端发送连接释放请求，然后服务端便进入 LAST-ACK 状态。客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态。该状态会持续 2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 CLOSED 状态。当服务端收到确认应答后，也便进入 CLOSED 状态。

### 7.一个完整的URL的组成部分

以下面的URL为例：http://www.aspxfans.com:8080/news/index.asp?boardID=5&ID=24618&page=1#name

从上面的URL可以看出，一个完整的URL包括以下几部分：

- 协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在"HTTP"后面的“//”为分隔符；
- 域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用
- 端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口（HTTP协议默认端口是80，HTTPS协议默认端口是443）；
- 虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”；
- 文件名部分：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名；
- 锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分；
- 参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5&ID=24618&page=1”。参数可以允许有多个参数，参数与参数之间用“&”作为分隔符。

### 8. 端口号的作用

一台主机(对应一个IP地址)可以提供很多服务，比如web服务，ftp服务等。如果只有一个IP，就无法区分不同的网络服务，所以采用”IP+端口号”来区分不同的服务。

### 9.常见的状态码

HTTP 态码可分为 5 大类：

#### 1XX：消息状态码

- 100：Continue 继续。客户端应继续其请求。
- 101：Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议。
- 102：继续处理 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。

#### 2XX：成功状态码

- 200：OK 请求成功。一般用于 GET 与 POST 请求。
- 201：Created 已创建。成功请求并创建了新的资源。
- 202：Accepted 已接受。已经接受请求，但未处理完成。
- 203：Non-Authoritative Information    非授权信息。请求成功。但返回的 meta 信息不在原始的服务器，而是一个副本。
- 204：No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档。
- 205：Reset Content    重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域。
- 206：Partial Content     部分内容。服务器成功处理了部分 GET 请求。

#### 3XX：重定向状态码

- 300：Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择。

- 301：Moved Permanently 永久移动。请求的资源已被永久的移动到新 URI，返回信息会包括新的 URI，浏览器会自动定向到新 URI。今后任何新的请求都应使用新的 URI 代替。
- 302：Found 临时移动，与 301 类似。但资源只是临时被移动。客户端应继续使用原有URI。
- 303：See Other  查看其它地址。与 301 类似。使用 GET 和 POST 请求查看。
- 304：Not Modified  未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源。
- 305：Use Proxy    使用代理。所请求的资源必须通过代理访问。
- 306：Unused 已经被废弃的 HTTP 状态码。
- 307：Temporary Redirect 临时重定向。与 302 类似。使用 GET 请求重定向。

#### 4XX：客户端错误状态码

- 400：Bad Request 客户端请求的语法错误，服务器无法理解。
- 401：Unauthorized 请求要求用户的身份认证。
- 402：Payment Required    保留，将来使用。
- 403：Forbidden    服务器理解请求客户端的请求，但是拒绝执行此请求。
- 404：Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面。
- 405：Method Not Allowed 客户端请求中的方法被禁止。
- 406：Not Acceptable 服务器无法根据客户端请求的内容特性完成请求。
- 407：Proxy Authentication Required 请求要求代理的身份认证，与 401 类似，但请求者应当使用代理进行授权。
- 408：Request Time-out 服务器等待客户端发送的请求时间过长，超时。
- 409：Conflict 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突。
- 410：Gone 客户端请求的资源已经不存在。410 不同于 404，如果资源以前有现在被永久删除了可使用 410 代码，网站设计人员可通过 301 代码指定资源的新位置。
- 411：Length Required 服务器无法处理客户端发送的不带 Content-Length 的请求信息。
- 412：Precondition Failed 客户端请求信息的先决条件错误。
- 413：Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个 Retry-After 的响应信息。
- 414：Request-URI Too Large    请求的 URI 过长（URI通常为网址），服务器无法处理。
- 415：Unsupported Media Type    服务器无法处理请求附带的媒体格式。
- 416：Requested range not satisfiable    客户端请求的范围无效。
- 417：Expectation Failed    服务器无法满足 Expect 的请求头信息。

#### 5XX：服务端错误状态码

- 500：Internal Server Error 服务器内部错误，无法完成请求。
- 501：Not Implemented 服务器不支持请求的功能，无法完成请求。
- 502：Bad Gateway 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应。
- 503：Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中。
- 504：Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求。
- 505：HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理。

## 二、DNS

**DNS协议**：DNS 是域名系统 (Domain Name System) 的缩写，提供的是一种主机名到 IP 地址的转换服务，就是我们常说的域名系统。它是一个由分层的 DNS 服务器组成的分布式数据库，是定义了主机如何查询这个分布式数据库的方式的应用层协议。能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

**作用：** 将域名解析为IP地址，客户端向DNS服务器（DNS服务器有自己的IP地址）发送域名查询请求，DNS服务器告知客户机Web服务器的 IP 地址。

**DNS完整的查询过程**

DNS服务器解析域名的过程：

- 首先会在浏览器的缓存中查找对应的IP地址，如果查找到直接返回，若找不到继续下一步
- 将请求发送给本地DNS服务器，在本地域名服务器缓存中查询，如果查找到，就直接将查找结果返回，若找不到继续下一步
- 本地DNS服务器向根域名服务器发送请求，根域名服务器会返回一个所查询域的顶级域名服务器地址
- 本地DNS服务器向顶级域名服务器发送请求，接受请求的服务器查询自己的缓存，如果有记录，就返回查询结果，如果没有就返回相关的下一级的权威域名服务器的地址
- 本地DNS服务器向权威域名服务器发送请求，域名服务器返回对应的结果
- 本地DNS服务器将返回结果保存在缓存中，便于下次使用
- 本地DNS服务器将返回结果返回给浏览器

比如要查询 [www.baidu.com](http://www.baidu.com/) 的 IP 地址，首先会在浏览器的缓存中查找是否有该域名的缓存，如果不存在就将请求发送到本地的 DNS 服务器中，本地DNS服务器会判断是否存在该域名的缓存，如果不存在，则向根域名服务器发送一个请求，根域名服务器返回负责 .com 的顶级域名服务器的 IP 地址的列表。然后本地 DNS 服务器再向其中一个负责 .com 的顶级域名服务器发送一个请求，负责 .com 的顶级域名服务器返回负责 .baidu 的权威域名服务器的 IP 地址列表。然后本地 DNS 服务器再向其中一个权威域名服务器发送一个请求，最后权威域名服务器返回一个对应的主机名的 IP 地址列表。

**迭代查询与递归查询**

实际上，DNS解析是一个包含迭代查询和递归查询的过程。

- 递归查询指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归 查询，用户只需要发出一次查询请求。
- 迭代查询指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出 多次的查询请求。

一般我们向本地 DNS 服务器发送请求的方式就是递归查询，因为我们只需要发出一次请求，然后本地 DNS 服务器返回给我 们最终的请求结果。而本地 DNS 服务器向其他域名服务器请求的过程是迭代查询的过程，因为每一次域名服务器只返回单次 查询的结果，下一级的查询由本地 DNS 服务器自己进行。

## 三、网络模型

**OSI七层模型**

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705194034717.png" alt="image-20220705194034717" style="zoom: 80%;" />

![image-20220713101153972](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220713101153972.png)

#### 1.应用层

`OSI`参考模型中最靠近用户的一层，是**为计算机用户提供应用接口，也为用户直接提供各种网络服务**。我们常见应用层的网络服务协议有：

- 超文本传输 Http、Https （在客户端与服务器中经常会有数据的请求，这个时候就是会用到http(hyper text transfer protocol)(超文本传输协议)或者https。在后端设计数据接口时，我们常常使用到这个协议）

- 文本传输：FTP （在开发过程中，个人并没有涉及到，但是我想，在一些资源网站，比如百度网盘, 迅雷应该是基于此协议的。）
- 电子邮件：SMTP、POP3、IMAP （SMTP是simple mail transfer protocol（简单邮件传输协议）。在一个项目中，在用户邮箱验证码登录的功能时，使用到了这个协议）
- 动态主机配置：DHCP 
- 域名系统：DNS

#### 2.表示层

表示层提供**各种用于应用层数据的编码、转换、压缩和加密功能**,**确保一个系统的应用层发送的数据能被另一个系统的应用层识别。**如果必要，该层可提供一种标准表示形式，用于将计算机内部的多种数据格式转换成通信中采用的标准表示形式。数据压缩和加密也是表示层可提供的转换功能之一。在项目开发中，为了方便数据传输，可以使用`base64`对数据进行编解码。如果按功能来划分，**`base64`应该是工作在表示层。**

#### 3.会话层

会话层就是**负责建立、管理和终止表示层实体之间的通信会话**。该层的通信由不同设备中的应用程序之间的服务请求和响应组成。

#### 4.传输层

**传输层建立了主机端到端的链接**，传输层的作用是**为上层协议提供端到端的可靠和透明的数据传输服务**，包括处理**差错控制和流量控制**等问题。**该层向高层屏蔽了下层数据通信的细节**，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。我们通常说的，**TCP UDP**就是在这一层。端口号既是这里的“端”。

#### 5.网络层

本层通**过`IP`寻址来建立两个节点之间的连接**，为源端的运输层送来的分组，**选择合适的路由和交换节点，正确无误地按照地址传送给目的端的运输层**。就是通常说的IP层。这一层就是我们经常说的**IP协议层**（IPV4,IPV6等）。IP协议是Internet的基础。我们可以这样理解，网络层规定了数据包的传输路线，而传输层则规定了数据包的传输方式。

#### 6.数据链路层

完成网络之间相邻结点的**可靠**传输，通过**Mac地址进行差错控制**，将网络层交下来的 IP 数据报封装成帧，并在链路的两个相邻节点间传送帧，负责主机之间的**数据的可靠传输**。将比特组合成字节,再将字节组合成帧,用链路层地址 (以太网使用MAC地址)来访问介质,并进行差错检测。**物理层传输的是比特流，而[数据链路层](https://so.csdn.net/so/search?q=数据链路层&spm=1001.2101.3001.7020)传输的是帧**。
通过上面的描述，我们或许可以这样理解，网络层是规划了数据包的传输路线，而数据链路层就是传输路线。不过，在数据链路层上还增加了差错控制的功能。

#### 7.物理层

实际最终信号的传输是通过物理层实现的。**通过物理介质传输比特流。**规定了电平、速度和电缆针脚。常用设备有（各种物理设备）集线器、中继器、调制解调器、网线、双绞线、同轴电缆。这些都是物理层的传输介质。

**OSI七层模型通信特点**：对等通信
对等通信，为了使数据分组从源传送到目的地，**源端OSI模型的每一层都必须与目的端的对等层进行通信**，这种通信方式称为对等层通信。在每一层通信过程中，使用本层自己协议进行通信。

**TCP/IP五层协议**

![image-20220705195708933](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705195708933.png)



- 应用层 (application layer)：直接为应用进程提供服务。应用层协议定义的是应用进程间通讯和交互的规则，不同的应用有着不同的应用层协议，如 HTTP协议（万维网服务）、FTP协议（文件传输）、SMTP协议（电子邮件）、DNS（域名查询）等。
- 传输层 (transport layer)：有时也译为运输层，它负责为两台主机中的进程提供通信服务。该层主要有以下两种协议：
  ○ 传输控制协议 (Transmission Control Protocol，TCP)：提供面向连接的、可靠的数据传输服务，数据传输的基本单位是报文段（segment）；
  ○ 用户数据报协议 (User Datagram Protocol，UDP)：提供无连接的、尽最大努力的数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。
- 网络层 (internet layer)：有时也译为网际层，它负责为两台主机提供通信服务，并通过选择合适的路由将数据传递到目标主机。（IPV4,IPV6,ARP）
- 数据链路层 (data link layer)：负责将网络层交下来的 IP 数据报封装成帧，并在链路的两个相邻节点间传送帧，每一帧都包含数据和必要的控制信息（如同步信息、地址信息、差错控制等）。
- 物理层 (physical Layer)：确保数据可以在各种物理媒介上进行传输，为数据的传输提供可靠的环境。

![image-20220705200240443](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705200240443.png)

![image-20220705200306107](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705200306107.png)

![image-20220705200346426](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220705200346426.png)

## 四、TCP/UDP（传输层）

|              | UDP                                        | TCP                                                  |
| ------------ | ------------------------------------------ | ---------------------------------------------------- |
| 是否连接     | 无连接                                     | 面向连接                                             |
| 是否可靠     | 不可靠传输，不使用流量控制和拥塞控制       | 可靠传输（数据顺序和正确性），使用流量控制和拥塞控制 |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信                                     |
| 传输方式     | 面向报文                                   | 面向字节流                                           |
| 首部开销     | 首部开销小，仅8字节                        | 首部最小20字节，最大60字节                           |
| 适用场景     | 适用于实时应用，例如视频会议、直播         | 适用于要求可靠传输的应用，例如文件传输               |

### 1.TCP

![image-20220723165952571](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220723165952571.png)

TCP的全称是传输控制协议是**一种面向连接的、可靠的、基于字节流的传输层通信协议**。TCP类似于打电话，接通了，确认身份后，才开始通信

它有以下几个特点：
**1）面向连接**
面向连接，是指发送数据之前必须在两端建立连接。建立连接的方法是“三次握手”，这样能建立可靠的连接。建立连接，是为数据的可靠传输打下了基础。
**2）仅支持单播传输**
每条TCP传输连接只能有两个端点，只能进行点对点的数据传输，不支持多播和广播传输方式。
**3）面向字节流**
TCP不像UDP一样那样一个个报文独立地传输，而是在不保留报文边界的情况下以字节流方式进行传输。
**4）可靠传输**
通过tcp三次挥手和四次握手实现。对于可靠传输，判断丢包、误码靠的是TCP的段编号以及确认号。TCP为了保证报文传输的可靠，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的字节发回一个相应的确认(ACK)；如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据（假设丢失了）将会被重传。
**5）提供拥塞控制**
当网络出现拥塞的时候，TCP能够减小向网络注入数据的速率和数量，缓解拥塞。
**6）提供全双工通信**
TCP允许通信双方的应用程序在任何时候都能发送数据，因为TCP连接的两端都设有缓存，用来临时存放双向通信的数据。当然，TCP可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于MSS）

### 2.UDP

![image-20220723170021546](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220723170021546.png)

UDP的全称是用户数据报协议，在网络中它与TCP协议一样用于处理数据包，是一种无连接的协议。在OSI模型中，在传输层，处于IP协议的上一层。UDP有不提供数据包分组、组装和不能对数据包进行排序的缺点，也就是说，当报文发送之后，是无法得知其是否安全完整到达的。UDP类似于学校广播站，靠着广播报文直接进行通信

**特点：**
**1）面向无连接**
首先 UDP 是不需要和 TCP一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。并且也只是数据报文的搬运工，**不会对数据报文进行任何拆分和拼接操作。**

具体来说就是：

- 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了

- 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作

**2）有单播，多播，广播的功能**
UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。
**3）面向报文**
  发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文
**4）不可靠性**
首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。
并且收到什么数据就传递什么数据，并且也不会备份数据，**发送数据也不会关心对方是否已经正确、完整的接收到数据了。**

**5）没有拥塞控制**

再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，**一直会以恒定的速度发送数据**。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。

**5）头部开销小，传输数据报文时是很高效的。**

UDP 头部包含了以下几个数据：

- 两个十六位的端口号，分别为源端口（可选字段）和目标端口
- 整个数据报文的长度
- 整个数据报文的检验和（IPv4 可选字段），该字段用于发现头部信息和数据中的错误

因此 UDP 的头部开销小，只有8字节，相比 TCP 的至少20字节要少得多，在传输数据报文时是很高效的。

### 3.使用场景

- TCP应用场景： 效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有UDP高。例如：文件传输（准确高要求高、但是速度可以相对慢）、接受邮件、远程登录。
- UDP应用场景： 效率要求相对高，对准确性要求相对低的场景。例如：QQ聊天、在线视频、网络语音电话（即时通讯，速度要求高，但是出现偶尔断续不是太大问题，并且此处完全不可以使用重发机制）、广播通信（广播、多播）。

### 4.UDP协议为什么不可靠？

UDP在传输数据之前不需要先建立连接，远地主机的运输层在接收到UDP报文后，不需要确认，提供不可靠交付。总结就以下四点：

- 不保证消息交付：不确认，不重传，无超时
- 不保证交付顺序：不设置包序号，不重排，不会发生队首阻塞
- 不跟踪连接状态：不必建立连接或重启状态机
- 不进行拥塞控制：不内置客户端或网络反馈机制

### 5.三次握手 & 四次挥手

#### 1.三次握手

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220723163452200.png" alt="image-20220723163452200" style="zoom:80%;" />

1.刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态。

- 第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN，此时客户端处于 SYN_SEND 状态。
- 第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_REVD 的状态。
- 第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 ESTABLISHED 状态。服务器收到 ACK 报文之后，也处于 ESTABLISHED 状态，此时，双方已建立起了连接。

简单来说就是以下三步：

- 第一次握手：客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入 SYN-SENT 状态。
- 第二次握手：服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯初始序号，发送完成后便进入 SYN-RECEIVED 状态。
- 第三次握手：当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入 ESTABLISHED 状态，服务端收到这个应答后也进入 ESTABLISHED 状态，此时连接建立成功。

那为什么要三次握手呢？两次不行吗？

- 为了确认双方的接收能力和发送能力都正常
- 如果是用两次握手，则会出现下面这种情况：

>如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

**重点扩展**：

1. **SYN Flood攻击**

   SYN Flood（半开放攻击）是**一种拒绝服务（DDoS）攻击**。其目的是通过消耗所有可用的服务器资源使服务器不可用于合法流量。通过重复发送初始连接请求（SYN）数据包，攻击者能够压倒目标服务器机器上的所有可用端口，导致目标设备根本不响应合法流量。

   **原理**：我们可以发现，**三次握手** 属于一个协商的过程，也就是说客户端与服务端必须严格按照这个过程来进行，否则连接就不能建立。这时，如果客户端发送 **SYN包** 企图与服务端建立连接，但发送完 **SYN包** 后就不管，那会发送什么事情呢？

   - 客户端发送一个 **SYN包** 给服务端后就退出，而服务端接收到 **SYN包** 后，会回复一个 **SYN+ACK包** 给客户端，然后等待客户端回复一个 **ACK包**。

   但此时客户端并不会回复 **ACK包**，所以服务端只能一直等待直到超时。服务端超时后，会重发 **SYN+ACK包** 给客户端，默认会重试 5 次，而且每次等待的时间都会增加（可以参考 TCP 协议超时重传的实现）。

   - 另外，当服务端接收到 **SYN包** 后，会建立一个半连接状态的 Socket。所以，当客户端一直发送 **SYN包**，但不回复 **ACK包**，那么将会耗尽服务端的资源，这就是 **SYN Flood 攻击**。

   **防范手段：**

   - 增加 SYN 连接数：tcp_max_syn_backlog （只能延缓一下半连接队列爆满的情况）

   - 减少SYN+ACK重试次数：tcp_synack_retries（重试次数由 /proc/sys/net/ipv4/tcp_synack_retries控制，默认情况下是 5 次，而我们在被攻击的时候，调小这个值很有必要，可以减少重传的次数，加快连接取消的速度）

   - tcp_syncookies 机制：SYN Cookie是对TCP服务器端的三次握手做一些修改，专门用来防范SYN Flood攻击的一种手段

     - 在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。

     - 这个cookie作为将要返回的SYN ACK包的初始序列号。

     - 当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接。

2. **可以采用四次握手吗？**

   这个肯定可以。三次握手都可以保证连接成功了，何况是四次，但是会降低传输的效率。

3. ##### 第三次握手中，如果客户端的ACK未送达服务器，会怎样？

   Server端：由于Server没有收到ACK确认，因此会每隔 **3秒** (不确定)重发之前的SYN+ACK（默认重发五次，之后自动关闭连接进入CLOSED状态），Client收到后会重新传ACK给Server。

   Client端，会出现两种情况：

   1. 在Server进行超时重发的过程中，如果Client向服务器发送数据，数据头部的ACK是为1的，所以服务器收到数据之后会读取 ACK number，进入 establish 状态
   2. 在Server进入CLOSED状态之后，如果Client向服务器发送数据，服务器会以RST包应答。

4. #####  如果已经建立了连接，但客户端出现了故障怎么办？

   服务器每收到一次客户端的请求后都会重新复位一个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

5. ##### 初始序列号是什么？

    TCP连接的一方A，随机选择一个32位的序列号（Sequence Number）作为发送数据的初始序列号（Initial Sequence Number，ISN），比如为1000，以该序列号为原点，对要传送的数据进行编号：1001、1002...三次握手时，把这个初始序列号传送给另一方B，以便在传输数据时，B可以确认什么样的数据编号是合法的；同时在进行数据传输时，A还可以确认B收到的每一个字节，如果A收到了B的确认编号（acknowledge number）是2001，就说明编号为1001-2000的数据已经被B成功接受。

#### 2.四次挥手

![image-20220723164401825](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220723164401825.png)

简单来说就是以下四步：

- 第一次挥手：若客户端认为数据发送完成，则它需要向服务端发送连接释放请求。
- 第二次挥手：服务端收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明客户端到服务端的连接已经释放，不再接收客户端发的数据了。但是因为 TCP 连接是双向的，所以服务端仍旧可以发送数据给客户端。
- 第三次挥手：服务端如果此时还有没发完的数据会继续发送，完毕后会向客户端发送连接释放请求FIN，然后服务端便进入 LAST-ACK 状态。
- 第四次挥手：客户端收到释放请求后，向服务端发送确认应答，此时客户端进入 TIME-WAIT 状态。该状态会持续 **2MSL**（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有服务端的重发请求的话，就进入 CLOSED 状态。当服务端收到确认应答后，也便进入 CLOSED 状态。

**重要扩展：**

- ##### 为什么不能把服务器发送的ACK和FIN合并起来，变成三次挥手（CLOSE_WAIT状态意义是什么）？

  因为服务器收到客户端断开连接的请求时，可能还有一些数据没有发完，这时先回复ACK，表示接收到了断开连接的请求。等到数据发完之后再发FIN，断开服务器到客户端的数据传送。

- #####  如果第二次挥手时服务器的ACK没有送达客户端，会怎样？

  客户端没有收到ACK确认，会重新发送FIN请求。

- ##### 客户端TIME_WAIT状态的意义是什么？

  第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN，如果Client在2*MSL的时间内收到了FIN，就会重新发送ACK并再次等待2MSL，防止Server没有收到ACK而不断重发FIN。 MSL(Maximum Segment Lifetime)，指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

### 6.TCP如何保证数据的可靠性

**TCP主要通过校验和、确认应答序列号、超时重传、连接管理、流量控制、拥塞控制这6个方面来保证数据的可靠传输的。**

1、**检验和**：数据收发方在进行数据传输时，都会先计算校验和，如果不一致，就说明数据传输有误。

2、**确认应答，序列号**：TCP在进行数据传输时都是进行编号的，每次接收方返回ACK时都有确认序列号。然后发送方就知道哪些数据已经被接收，下次数据从哪里开始发送。如果有丢包，就重发。

3、**超时重传**：如果发送方发送数据一段时间后没有收到ACK，那么就重新发送数据。

4、**连接管理**：TCP通过三次握手建立连接，四次挥手断开连接。

5、**流量控制**：根据接收端的能力进行数据发送
TCP协议报头包含16位的窗口大小，接收方会在返回数据时，将自己的即时窗口大小填入，发送方就会根据报文中窗口的大小控制发送速度。

6、**拥塞控制**：会像探路一样，先发送小数据，防止拥塞
刚开始发送数据的时候，拥塞窗口是1，以后每次收到ACK，则拥塞窗口+1，然后将拥塞窗口和收到的窗口取较小值作为实际发送的窗口，如果发生超时重传，拥塞窗口重置为1。这样做的目的就是为了保证传输过程的高效性和可靠性。

**重传机制**

由于TCP的下层网络（网络层）可能出现丢失、重复或失序的情况，TCP协议提供可靠数据传输服务。为保证数据传输的正确性，TCP会重传其认为已丢失（包括报文中的比特错误）的包。TCP使用两套独立的机制来完成重传，一是基于时间，二是基于确认信息。

**方式一：超时重传**

- 超时重传，是 TCP 协议保证数据可靠性的另一个重要机制，其原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。
- 这个计时器一般略大于数据往返时间（RTT），通过Jacobson / Karels 算法得出
- 超时重传不是十分完美的重传方案，它有这些缺点：
  - 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。
  - 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。
  - 并且，对于 TCP，如果发生一次超时重传，时间间隔下次就会加倍。

**方式二：快速重传**

服务器如果收到乱序的包，也给客户端回复 ACK，只不过是重复的 ACK。

**方式三：带选择确认的重传（SACK）**

**方式四：重复SACK**

### 7.TCP粘包

默认情况下, TCP 连接会启⽤延迟传送算法 (Nagle 算法), 在数据发送之前缓存他们. 如果短时间有多个数据发送, 会缓冲到⼀起作⼀次发送 (缓冲⼤⼩⻅ socket.bufferSize ), 这样可以减少 IO 消耗提⾼性能。如果是传输⽂件的话, 那么根本不⽤处理粘包的问题, 来⼀个包拼⼀个包就好了。但是如果是多条消息, 或者是别的⽤途的数据那么就需要处理粘包.。

下面看⼀个例⼦, 连续调⽤两次 send 分别发送两段数据 data1 和 data2, 在接收端有以下⼏种常⻅的情况: 
A. 先接收到 data1, 然后接收到 data2 . 
B. 先接收到 data1 的部分数据, 然后接收到 data1 余下的部分以及 data2 的全部. 
C. 先接收到了 data1 的全部数据和 data2 的部分数据, 然后接收到了 data2 的余下的数据. 
D. ⼀次性接收到了 data1 和 data2 的全部数据. 

其中的 BCD 就是我们常⻅的粘包的情况. ⽽对于处理粘包的问题, 常⻅的解决⽅案有: 

- 多次发送之前间隔⼀个等待时间：只需要等上⼀段时间再进⾏下⼀次 send 就好, 适⽤于交互频率特别低的场景. 缺点也很明显, 对于⽐较频繁的场景⽽⾔传输效率实在太低，不过⼏乎不⽤做什么处理. 
- 关闭 Nagle 算法：关闭 Nagle 算法, 在 Node.js 中你可以通过 socket.setNoDelay() ⽅法来关闭 Nagle 算法, 让每⼀次 send 都不缓冲直接发送。该⽅法⽐较适⽤于每次发送的数据都⽐较⼤ (但不是⽂件那么⼤), 并且频率不是特别⾼的场景。如果是每次发送的数据量⽐较⼩, 并且频率特别⾼的, 关闭 Nagle 纯属⾃废武功。另外, 该⽅法不适⽤于⽹络较差的情况, 因为 Nagle 算法是在服务端进⾏的包合并情况, 但是如果短时间内客户端的⽹络情况不好, 或者应⽤层由于某些原因不能及时将 TCP 的数据 recv, 就会造成多个包在客户端缓冲从⽽粘包的情况。 (如果是在稳定的机房内部通信那么这个概率是⽐较⼩可以选择忽略的)  
- 进⾏封包/拆包：封包/拆包是⽬前业内常⻅的解决⽅案了。即给每个数据包在发送之前, 于其前/后放⼀些有特征的数据, 然后收到数据的时 候根据特征数据分割出来各个数据包。

### 8.为什么udp不会粘包？ 

- TCP协议是⾯向流的协议，UDP是⾯向消息的协议。UDP段都是⼀条消息，应⽤程序必须以消息为单位提取数据，**不能⼀次提取任意字节的数据** 
- UDP具有保护消息边界，在每个UDP包中就有了消息头（消息来源地址，端⼝等信息），这样对于接收端来说就容易进⾏区分处理了。传输协议把数据当作⼀条独⽴的消息在⽹上传输，接收端只能接收独⽴的消息。接收端⼀次只能接收发送端发出的⼀个数据包,如果⼀次接受数据的⼤⼩⼩于发送端⼀次发送的数据⼤⼩，就会丢失⼀部分数据，即使丢失，接受端也不会分两次去接收。

### 9.对WebSocket的理解

**定义：**

- WebSocket是一种网络通信协议，RFC6455定义了它的通信标准
- WebSocket是HTML5开始提供的一种**在单个TCP连接上进行全双工通讯**的协议，处于应用层，它基于**TCP传输协议，并复用HTTP的握手通道。浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接， 并进行双向数据传输**。WebSocket 的出现就解决了半双工通信（Http）的弊端，它最大的特点是：服务器可以向客户端主动推动消息，客户端也可以主动向服务器推送消息。

**WebSocket原理：**客户端向 WebSocket 服务器通知（notify）一个带有所有接收者ID（recipients IDs）的事件（event），服务器接收后立即通知所有活跃的（active）客户端，只有ID在接收者ID序列中的客户端才会处理这个事件。

**WebSocket 特点的如下：**

- 支持双向通信，实时性更强
- 可以发送文本，也可以发送二进制数据‘’
- 建立在TCP协议之上，服务端的实现比较容易
- 数据格式比较轻量，性能开销小，通信高效
- 没有同源限制，客户端可以与任意服务器通信
- 协议标识符是ws（如果加密，则为wss），服务器网址就是 URL
- 与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。



### 10.场景应用分析

1.后端tcp连接占满了是什么原因？

4.视频上传有哪些技术难点？视频封面怎么做

5.前端分片的api叫什么



9.proxy的优缺点

10.前端的前沿技术



12.http一条通道能不能发送多个请求？tcp和http的关系

13.TCP拥塞控制，有什么缺点 TCP流量控制

14.



# 二、计算机操作系统

### 一. 并发和并行

**并发**就是在一段时间内，多个任务都会被处理；但在某一时刻，只有一个任务在执行。单核处理器做到的并发，其实是利用时间片的轮转，例如有两个进程A和B，A运行一个时间片之后，切换到B，B运行一个时间片之后又切换到A。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。

**并行**就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。

## 二. 进程

一个进程由三部分组成：进程控制块PCB（Process Control Block），有关程序段，该程序段对其操作的数据结构集。

>**进程的PCB是系统感知进程的唯一实体。**里面记录了进程的各种信息，这些信息都包括:
>
>1. **描述信息**：进程的标识号、用户标识号、家族关系
>2. **控制信息**：进程当前状态、进程优先级、程序开始地址、计时信息、通信信息
>3. **资源管理信息**：管理内存数据结构的指针、文件系统的指针等包括存储器的信息，IO设备、文件系统的信息。
>4. **CPU现场保护结构**：各个寄存器的内容

### **进程上下文**

对于单核单线程 CPU 而言，在某一时刻只能执行一条 CPU 指令。上下文切换 (Context Switch) 是一种将 CPU 资源从一个进程分配给另一个进程的机制。从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。在切换的过程中，操作系统需要先存储当前进程的状态 (包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。常见的进程上下文调度算法包括：

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220724201823956.png" alt="image-20220724201823956" style="zoom:50%;" />

### **进程间通信：**

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220724202308372.png" alt="image-20220724202308372" style="zoom: 80%;" />



- 共享内存：两个进程对共享空间的访问是互斥的，数据的形式、存放位置由进程控制，操作系统只负责共享空间和互斥工具
- 管道：管道采用半双工通信，管道数据以字符流的形式写入管道
- 信号量：
- 信号：

### **进程和线程的区别**

> **线程是进程当中的⼀条执⾏流程。**

线程与进程的⽐较如下：

- 调度：**进程是资源（包括内存、打开的⽂件等）分配的单位**，**线程是 CPU 调度的单位**；
- 资源：进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
- 拥有资源：线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
- 系统开销：线程能减少并发执⾏的时间和空间开销——创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。

### **线程上下文切换**

这还得看线程是不是属于同⼀个进程：

- 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
- **当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据**；

所以，线程的上下⽂切换相⽐进程，开销要⼩很多。

### **线程同步**

同步解决的多线程操作共享资源的问题，目的是不管线程之间的执行如何穿插，最后的结果都是正确的。

**临界区**：我们把对共享资源访问的程序片段称为`临界区`，我们希望这段代码是`互斥`的，**保证在某时刻只能被一个线程执行**，也就是说一个线程在临界区执行时，其它线程应该被阻止进入临界区。(临界区不仅针对线程，同样针对进程)。实现临界区有两种方式，包括加锁和信号量

>锁：使⽤加锁操作和解锁操作可以解决并发线程/进程的互斥问题。任何想进⼊临界区的线程，必须先执⾏加锁操作。若加锁操作顺利通过，则线程可进⼊临界区；在完成对临界资源的访问后再执⾏解锁操作，以释放该临界资源。
>
>**信号量**：是操作系统提供的⼀种协调共享资源访问的⽅法。通常**信号量表示资源的数量**，对应的变量是⼀个整型（ sem ）变量。另外，还有**两个原⼦操作的系统调⽤函数来控制信号量的**

## 三.死锁

### **定义**

在两个或者多个并发线程中，如果每个线程持有某种资源，而又等待其它线程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组线程产生了死锁。通俗的讲就是两个或多个线程无限期的阻塞、相互等待的一种状态。

### **产生条件**

- **互斥条件**：指线程对己经获取到的资源进行它性使用，即该资源同时只由一个线程占用。如果此时还有其它线程请求获取获取该资源，则请求者只能等待，直至占有资源的线程释放该资源。
- **请求并持有条件**：指一个线程己经持有了至少一个资源，但又提出了新的资源请求，而新资源己被其它线程占有，所以当前线程会被阻塞，但阻塞 的同时并不释放自己已经获取的资源。
- **不可剥夺条件**：指线程获取到的资源在自己使用完之前不能被其它线程抢占，只有在自己使用完毕后才由自己释放该资源。
- **环路等待条件**：指在发生死锁时，必然存在一个线程——资源的环形链，即线程集合 {T0，T1，T2,…… ，Tn} 中 T0 正在等待一 T1 占用的资源，Tl1正在等待 T2用的资源，…… Tn 在等待己被 T0占用的资源。

### 如何避免死锁呢？

产⽣死锁的有四个必要条件：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。避免死锁，破坏其中的一个就可以。

**消除互斥条件**

这个是没法实现，因为很多资源就是只能被一个线程占用，例如锁。

**消除请求并持有条件**

消除这个条件的办法很简单，就是一个线程一次请求其所需要的所有资源。

**消除不可剥夺条件**

占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可剥夺这个条件就破坏掉了。

**消除环路等待条件**

可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后就不存在环路了。

### 活锁和饥饿锁

**饥饿锁：**

饥饿锁，这个饥饿指的是资源饥饿，某个线程一直等不到它所需要的资源，从而无法向前推进，就像一个人因为饥饿无法成长。

**活锁：**

在活锁状态下，处于活锁线程组里的线程状态可以改变，但是整个活锁组的线程无法推进。活锁可以用两个人过一条很窄的小桥来比喻：为了让对方先过，两个人都往旁边让，但两个人总是让到同一边。这样，虽然两个人的状态一直在变化，但却都无法往前推进。

### 四、内存管理

#### **虚拟内存**

我们实际的物理内存主要是主存，但是物理主存空间有限，所以一般现代操作系统都会想办法把一部分内存块放到磁盘中，用到的时候再装入主存，但是对用户程序而言，是不需要注意实际的物理内存的，为什么呢？因为有`虚拟内存`的机制。

**简单说，虚拟内存是操作系统提供的⼀种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**每个进程都有自己独立的地址空间，再由操作系统映射到到实际的物理内存。

于是，这⾥就引出了两种地址的概念：

- 程序所使⽤的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）

- 实际存在硬件⾥⾯的空间地址叫**物理内存地址**（*Physical Memory Address*）。

虚拟地址和物理地址通过段表映射，段表主要包括**段号**、段的界限。

<img src="C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220724214714283.png" alt="image-20220724214714283" style="zoom:67%;" />

#### 用户态和内核态

>**内核**：内核是一个计算机程序，它是操作系统的核心，提供了操作系统最核心的能力，可以控制操作系统中所有的内容。

内核具有很⾼的权限，可以控制 cpu、内存、硬盘等硬件，出于权限控制的考虑，因此⼤多数操作系统，把内存分成了两个区域：

- 内核空间，这个内存空间只有内核程序可以访问；
- ⽤户空间，这个内存空间专⻔给应⽤程序使⽤，权限比较小；

**⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间**。因此，当程序使⽤⽤户空间时，我们常说该程序在**⽤户态**执⾏，⽽当程序使内核空间时，程序则在**内核态**执⾏。

**用户态和内核态的切换**：

应⽤程序如果需要进⼊内核空间，就需要通过系统调⽤，来进入内核态：

![image-20220725202959146](C:\Users\SFONE\AppData\Roaming\Typora\typora-user-images\image-20220725202959146.png)

内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。